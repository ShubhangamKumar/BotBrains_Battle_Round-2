To program a Two Wheeled Self-Balancing Robot (TWSBR) for delivering a parcel to a consumer's doorstep, navigating traffic, turns, and obstacles, we need to integrate hardware components, develop control algorithms, and write navigation software. Below, I'll outline the approach and provide sample code snippets to substantiate the claim.

1.)Hardware Components
   i.Microcontroller/Processor: Raspberry Pi or Arduino with a real-time operating system (RTOS).
   ii.Motors: Brushless DC motors with encoders for precise control.
   iii.Sensors:
       a.IMU (Inertial Measurement Unit): Gyroscope and accelerometer.
       b.LiDAR/Ultrasonic Sensors: For obstacle detection and distance measurement.
       c.Camera: For visual navigation and object detection.
   iv.Motor Drivers: To control the motors based on the microcontroller signals.
   v.Communication Module: Wi-Fi or 4G/5G for remote control and updates.
   vi.Power Supply: Batteries to power the robot and all components.

2.)Circuitry
   Connect the components to the microcontroller. The key connections are:
   i.IMU to I2C or SPI pins.
   ii.LiDAR/Ultrasonic sensors to GPIO pins.
   iii.Motors to motor drivers, which are controlled by PWM signals from the microcontroller.
   iv.Camera to a USB or dedicated camera interface.

Here's a basic diagram:

   +---------------------+
   |   Microcontroller   |
   |---------------------|
   |   GPIO      |  IMU  |
   |   Pins      |-------|
   |   LiDAR/    | Motor |
   |   Ultrasonic| Driver|
   +-------------+-------+
                 |  Motors
                 +------+

3.)Control Algorithm
  i.Balancing Control:
    Use a PID controller to maintain balance based on the IMU readings.

  ii.Navigation and Obstacle Avoidance:
     Combine sensor data from LiDAR/Ultrasonic sensors and the camera to navigate and avoid obstacles.

4.)Programming the Robot
   Language: Python (for its simplicity and robust libraries for robotics)

PID Controller for Balancing

import time
import board
import adafruit_mpu6050

# Initialize IMU
i2c = board.I2C()
mpu = adafruit_mpu6050.MPU6050(i2c)

# PID parameters
Kp = 1.0
Ki = 0.0
Kd = 0.1

setpoint = 0.0  # Desired angle (upright position)
integral = 0.0
previous_error = 0.0

def pid_control(angle, dt):
    global integral, previous_error
    error = setpoint - angle
    integral += error * dt
    derivative = (error - previous_error) / dt
    output = Kp * error + Ki * integral + Kd * derivative
    previous_error = error
    return output

while True:
    start_time = time.time()
    
    # Read angle from IMU
    accel_x, accel_y, accel_z = mpu.acceleration
    angle = calculate_angle(accel_x, accel_y, accel_z)
    
    # Compute control output
    dt = time.time() - start_time
    control_signal = pid_control(angle, dt)
    
    # Apply control signal to motors (pseudo code)
    set_motor_speed(control_signal)

    time.sleep(0.01)

Navigation Algorithm

import RPi.GPIO as GPIO
import cv2
import numpy as np

# GPIO setup
GPIO.setmode(GPIO.BCM)
TRIG = 23
ECHO = 24
GPIO.setup(TRIG, GPIO.OUT)
GPIO.setup(ECHO, GPIO.IN)

# Camera setup
cap = cv2.VideoCapture(0)

def measure_distance():
    GPIO.output(TRIG, True)
    time.sleep(0.00001)
    GPIO.output(TRIG, False)
    start = time.time()
    stop = time.time()
    while GPIO.input(ECHO) == 0:
        start = time.time()
    while GPIO.input(ECHO) == 1:
        stop = time.time()
    elapsed = stop - start
    distance = (elapsed * 34300) / 2
    return distance

while True:
    # Capture frame from camera
    ret, frame = cap.read()
    
    # Object detection and obstacle avoidance (simple color detection)
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    lower_red = np.array([0, 100, 100])
    upper_red = np.array([10, 255, 255])
    mask = cv2.inRange(hsv, lower_red, upper_red)
    
    # Navigation logic (pseudo code)
    if np.sum(mask) > 1000:
        avoid_obstacle()
    else:
        move_forward()

    # Distance measurement
    distance = measure_distance()
    if distance < 30:
        stop_movement()
        plan_alternate_path()

    time.sleep(0.1)

cap.release()
GPIO.cleanup()

5.)System Integration
  i.Combining Balancing and Navigation:
    The balancing algorithm runs continuously, ensuring the robot stays upright. The navigation algorithm adjusts the robot's trajectory based on sensor inputs, maintaining balance while moving towards the destination.

  ii.Parcel Delivery Task:
     a.Path Planning: Use pre-mapped routes or dynamic path planning algorithms like A* or Dijkstra's.
     b.Localization: Utilize GPS or SLAM (Simultaneous Localization and Mapping) for determining the robot's position.

High-Level Control Flow

def main():
    while not at_destination():
        # Balance the robot
        balance()
        
        # Navigate
        distance = measure_distance()
        if distance < 30:
            avoid_obstacle()
        else:
            move_towards_goal()
            
        # Monitor sensors and adjust
        adjust_control_parameters()
        
    deliver_parcel()

if __name__ == "__main__":
    main()

Conclusion
By integrating advanced sensors, control algorithms, and real-time processing, the TWSBR can effectively navigate to deliver parcels. The provided code outlines the fundamental aspects of balancing and navigation, and additional refinement can enhance performance based on specific requirements and environmental conditions.
